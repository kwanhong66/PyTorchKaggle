{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic_comment_classification_bert_simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0GF1xjChVYale4Wo1yRAq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a7ae6b5756e43deada75f114440fe5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_345119d532fa41c09d9a6a8b024c46c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a31f0d15f33d4ca38ea50be2345f0999",
              "IPY_MODEL_6ceca2c27ded4797a4b2166b4e6e5e01"
            ]
          }
        },
        "345119d532fa41c09d9a6a8b024c46c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a31f0d15f33d4ca38ea50be2345f0999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c163ede0f6b84c10aa7bb37347b4e34b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f59baf1f89604f32847982d9dee4b0e5"
          }
        },
        "6ceca2c27ded4797a4b2166b4e6e5e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78b4c37b54fd44c28e874efa3f240d53",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 807kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f73a8e6324542b3b566c7ad86fdc565"
          }
        },
        "c163ede0f6b84c10aa7bb37347b4e34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f59baf1f89604f32847982d9dee4b0e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78b4c37b54fd44c28e874efa3f240d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f73a8e6324542b3b566c7ad86fdc565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwanhong66/PyTorchKaggle/blob/master/Toxic_comment_classification_bert_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-KwORM3e_5p"
      },
      "source": [
        "## PyTorch x Kaggle\n",
        "\n",
        "- kaggle: Toxic comment classification challenge\n",
        "  - https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
        "\n",
        "- notebook\n",
        "  - https://www.kaggle.com/hawkeoni/pytorch-simple-bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GGxkpucfT8D"
      },
      "source": [
        "## Dataset with Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0wvAbJnfW2_"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBr6K3c_fZv8",
        "outputId": "d19f815e-ee9d-4770-b01a-497a8bdb840c"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/kwanhong66/KaggleShoveling/master/token/kaggle.json'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-25 05:06:52--  https://raw.githubusercontent.com/kwanhong66/KaggleShoveling/master/token/kaggle.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63 [text/plain]\n",
            "Saving to: ‘kaggle.json’\n",
            "\n",
            "\rkaggle.json           0%[                    ]       0  --.-KB/s               \rkaggle.json         100%[===================>]      63  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-25 05:06:52 (3.28 MB/s) - ‘kaggle.json’ saved [63/63]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM3uAi94fgbS"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrgcKqpffqCW"
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6o4w-axf2ql",
        "outputId": "2fc5250d-346b-4e51-c09d-4906cefe3773"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "ref                                                          title                                           size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  \n",
            "babyoda/women-entrepreneurship-and-labor-force               Women Entrepreneurship and Labor Force           1KB  2020-11-21 08:38:51            103  \n",
            "sakshigoyal7/credit-card-customers                           Credit Card customers                          379KB  2020-11-19 07:38:44            179  \n",
            "imoore/2020-us-general-election-turnout-rates                2020 US General Election Turnout rates           4KB  2020-11-19 17:13:32             72  \n",
            "szymonjanowski/internet-articles-data-with-users-engagement  Internet news data with readers engagement       3MB  2020-11-21 17:09:57             44  \n",
            "alexgude/california-traffic-collision-data-from-switrs       California Traffic Collision Data from SWITRS    1GB  2020-11-22 16:51:55             25  \n",
            "afrniomelo/3w-dataset                                        3W Dataset - Undesirable events in oil wells   658MB  2020-11-21 21:22:49              6  \n",
            "patrickb1912/ipl-complete-dataset-20082020                   IPL Complete Dataset (2008-2020)                 1MB  2020-11-23 06:53:37             36  \n",
            "mrmorj/us-politicians-twitter-dataset                        US Politicians Twitter Dataset                  68KB  2020-11-23 09:54:05             16  \n",
            "arioboo/clumps-in-vela-galaxy-images                         Clumps in VELA galaxy images                     8MB  2020-11-23 13:42:09              1  \n",
            "unanimad/us-election-2020                                    US Election 2020                               428KB  2020-11-24 12:57:57           8663  \n",
            "shivamb/netflix-shows                                        Netflix Movies and TV Shows                    971KB  2020-01-20 07:33:56          63958  \n",
            "antgoldbloom/covid19-data-from-john-hopkins-university       COVID-19 data from John Hopkins University       3MB  2020-11-24 06:04:02           4474  \n",
            "manchunhui/us-election-2020-tweets                           US Election 2020 Tweets                        353MB  2020-11-09 18:51:59           3435  \n",
            "sootersaalu/amazon-top-50-bestselling-books-2009-2019        Amazon Top 50 Bestselling Books 2009 - 2019     15KB  2020-10-13 09:39:21           5899  \n",
            "terenceshin/covid19s-impact-on-airport-traffic               COVID-19's Impact on Airport Traffic           106KB  2020-10-19 12:40:17           5353  \n",
            "nehaprabhavalkar/indian-food-101                             Indian Food 101                                  7KB  2020-09-30 06:23:43           8217  \n",
            "datasnaek/youtube-new                                        Trending YouTube Video Statistics              201MB  2019-06-03 00:56:47         117011  \n",
            "zynicide/wine-reviews                                        Wine Reviews                                    51MB  2017-11-27 17:08:04         120302  \n",
            "google/tinyquickdraw                                         QuickDraw Sketches                              11GB  2018-04-18 19:38:04           2510  \n",
            "karangadiya/fifa19                                           FIFA 19 complete player dataset                  2MB  2018-12-21 03:52:59         105846  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCTQRknegDql",
        "outputId": "3bfc12bd-4610-4e2d-ba61-91f5fbc3f98c"
      },
      "source": [
        "!kaggle competitions download jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 98% 23.0M/23.4M [00:00<00:00, 11.1MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 32.1MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 95.3MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 65% 17.0M/26.3M [00:00<00:00, 20.5MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 41.5MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 100MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0gCAfdCgmDv"
      },
      "source": [
        "!mkdir input"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8cUgqrHgq63",
        "outputId": "0f96d5c1-ebf5-43b0-d224-80b131423817"
      },
      "source": [
        "!unzip '*.zip' -d ./input/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: ./input/train.csv       \n",
            "\n",
            "Archive:  test.csv.zip\n",
            "  inflating: ./input/test.csv        \n",
            "\n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: ./input/test_labels.csv  \n",
            "\n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: ./input/sample_submission.csv  \n",
            "\n",
            "4 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GiGUEf8f-BH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOCx6bRoecEi"
      },
      "source": [
        "install trasnformers for using bert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxXYow3ndL_c",
        "outputId": "2487fe82-fbc0-4fc9-c8f2-afefcf1df474"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 27.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=0c89d99c61deaa979bca44fd839b331d4d114c525dbee296fff71a6bd31ad337\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDArInhJeylB"
      },
      "source": [
        "import os\n",
        "\n",
        "from typing import Tuple, List\n",
        "from functools import partial\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup, BertPreTrainedModel\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from tqdm import tqdm "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-G3zxj8zgVM",
        "outputId": "d01ac8f8-6775-40ca-c0bc-d78c491ef507"
      },
      "source": [
        "input_file_path = './input/'\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(input_file_path, 'train.csv'))\n",
        "\n",
        "print(train_df.shape)\n",
        "print(list(train_df.columns))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159571, 8)\n",
            "['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "oYmmVJXI1pMr",
        "outputId": "4fc0da96-efa3-4de0-fa65-26bfe803bff8"
      },
      "source": [
        "train_df.head(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN5GfhKK2Gwa",
        "outputId": "31ef31ed-1d86-492e-d320-9fa45349617d"
      },
      "source": [
        "train_split_df, val_split_df = train_test_split(train_df, test_size=0.05)\n",
        "\n",
        "print(train_split_df.shape)\n",
        "print(val_split_df.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(151592, 8)\n",
            "(7979, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0a7ae6b5756e43deada75f114440fe5a",
            "345119d532fa41c09d9a6a8b024c46c0",
            "a31f0d15f33d4ca38ea50be2345f0999",
            "6ceca2c27ded4797a4b2166b4e6e5e01",
            "c163ede0f6b84c10aa7bb37347b4e34b",
            "f59baf1f89604f32847982d9dee4b0e5",
            "78b4c37b54fd44c28e874efa3f240d53",
            "9f73a8e6324542b3b566c7ad86fdc565"
          ]
        },
        "id": "N5Xe6J1A0Ewf",
        "outputId": "b33e0d09-aad0-492f-9f25-0a545705b0f3"
      },
      "source": [
        "bert_model_name = 'bert-base-cased' #@param {type:\"string\"}\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "assert tokenizer.pad_token_id == 0, \"Padding vlaue used in masks is set to zero, please change it everywhere\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a7ae6b5756e43deada75f114440fe5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aezHBlJLhrMN"
      },
      "source": [
        "## Preparing dataset\n",
        "\n",
        "- Using torch `Dataset`, creates custom dataset for input data\n",
        "- inheriting `torch.utils.data.Dataset`\n",
        "  - \\_\\_init\\_\\_ \n",
        "  - \\_\\_len\\_\\_ \n",
        "  - \\_\\_getitem\\_\\_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scXLOvU8hop1"
      },
      "source": [
        "class ToxicDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer: BertTokenizer, dataframe: pd.DataFrame, lazy: bool=False):\n",
        "      self.tokenizer = tokenizer\n",
        "      self.pad_idx = tokenizer.pad_token_id\n",
        "      self.lazy = lazy  # data conversion laziness\n",
        "\n",
        "      if not self.lazy:\n",
        "        self.X = []\n",
        "        self.Y = []\n",
        "        for i, (row) in tqdm(dataframe.iterrows()):  # convert data into tensor\n",
        "          x, y = self.row_to_tensor(self.tokenizer, row)\n",
        "          self.X.append(x)\n",
        "          self.Y.append(y)\n",
        "      else:\n",
        "        self.df = dataframe\n",
        "\n",
        "    @staticmethod  \n",
        "    def row_to_tensor(tokenizer: BertTokenizer, row: pd.Series) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
        "      tokens = tokenizer.encode(row['comment_text'], add_special_tokens=True)\n",
        "      if len(tokens) > 120:\n",
        "        tokens = tokens[:119] + [tokens[-1]]\n",
        "      x = torch.LongTensor(tokens)\n",
        "      y = torch.FloatTensor(row[['toxic', 'severe_toxic', 'obscene', 'threat',\n",
        "                                 'insult', 'identity_hate']])\n",
        "      return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "      if self.lazy:\n",
        "        return len(self.df)\n",
        "      else:\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
        "      if not self.lazy:\n",
        "        return self.X[index], self.Y[index]\n",
        "      else:\n",
        "        return self.row_to_tensor(self.tokenizer, self.df.iloc[index])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxlBUyat_rBK"
      },
      "source": [
        "* collate_fn\n",
        "  - mini-batch를 구성하기 위해 데이터를 묶어주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfX9uH5c4eVd"
      },
      "source": [
        "# merges a list of samples to form a mini-batch\n",
        "def collate_fn(batch: List[Tuple[torch.LongTensor, torch.LongTensor]], device: torch.device) \\\n",
        "      -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
        "      x, y = list(zip(*batch))\n",
        "      x = pad_sequence(x, batch_first=True, padding_value=0)  # if batch_fist, B x T x *\n",
        "      y = torch.stack(y)\n",
        "      return x.to(device), y.to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM91PAAfB4V0"
      },
      "source": [
        "* Sampler는 index를 컨트롤하는 방법\n",
        "* dataset에서 data loading시에 indice/keys의 순서를 지정하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf4Dp9r4_djY"
      },
      "source": [
        "train_dataset = ToxicDataset(tokenizer, train_split_df, lazy=True)\n",
        "dev_dataset = ToxicDataset(tokenizer, val_split_df, lazy=True)\n",
        "collate_fn = partial(collate_fn, device=device)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "dev_sampler = RandomSampler(dev_dataset)\n",
        "\n",
        "# Dataset, Sampler, collate_fn -> DataLoader\n",
        "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
        "                            sampler=train_sampler, collate_fn=collate_fn)\n",
        "dev_iterator = DataLoader(dev_dataset, batch_size=BATCH_SIZE,\n",
        "                          sampler=dev_sampler, collate_fn=collate_fn)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht1EvpMTEtLM"
      },
      "source": [
        "## Simple BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jBDrM9jEv5I"
      },
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, bert: BertModel, num_classes: int):\n",
        "    super().__init__()\n",
        "    self.bert = bert\n",
        "    self.classifier = nn.Linear(bert.config.hidden_size, num_classes)  # in_features, out_features\n",
        "\n",
        "  def forward(self, input_ids, attention_mask=None, token_type_ids=None, \n",
        "              position_ids=None, head_mask=None, labels=None):\n",
        "    outputs = self.bert(input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        position_ids=position_ids,\n",
        "                        head_mask=head_mask)\n",
        "    cls_output = outputs[1]  # batch, hidden\n",
        "    cls_output = self.classifier(cls_output)  # batch, 6(classes)\n",
        "    cls_output = torch.sigmoid(cls_output)  # sigmoid from logit to probability\n",
        "    criterion = nn.BCELoss()  # loss function\n",
        "    loss = 0\n",
        "    if labels is not None:\n",
        "      loss = criterion(cls_output, labels)\n",
        "    return loss, cls_output"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFdu4WzbISPZ"
      },
      "source": [
        "model = BertClassifier(BertModel.from_pretrained(bert_model_name), 6).to(device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al4HZNe1I5rU"
      },
      "source": [
        "* Training and evaluation loops\n",
        "\n",
        "* Training\n",
        "  - set train mode: model.train()\n",
        "  - dataset iterator loop\n",
        "  - model forwarding with data\n",
        "  - backpropagation: loss.backward()\n",
        "  - perform optimization step: optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cue1ch2IfWD"
      },
      "source": [
        "def train(model, iterator, optimizer, scheduler):\n",
        "  model.train()  # set train mode\n",
        "  total_loss = 0 \n",
        "  for x, y in tqdm(iterator):\n",
        "    optimizer.zero_grad()  # set gradients to zero\n",
        "    mask = (x != 0).float()\n",
        "    loss, outputs = model(x, attention_mask=mask, labels=y)\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "  print(f\"Train loss {total_loss / len(iterator)}\")\n",
        "\n",
        "def evaluate(model, iterator):\n",
        "  model.eval()  # set eval mode\n",
        "  pred = []\n",
        "  true = []\n",
        "  with torch.no_grad():\n",
        "    total_loss = 0\n",
        "    for x, y in tqdm(iterator):\n",
        "      mask = (x != 0).float()\n",
        "      loss, outputs = model(x, attention_mask=mask, labels=y)\n",
        "      total_loss += loss\n",
        "      true += y.cpu().numpy().tolist()\n",
        "      pred += outputs.cpu().numpy().tolist()\n",
        "  true = np.array(true)\n",
        "  pred = np.array(pred)\n",
        "  for i, name in enumerate(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
        "                            'identity_hate']):\n",
        "    print(f\"{name} roc_auc {roc_auc_score(true[:, i], pred[:, i])}\")\n",
        "  print(f\"Evaluate loss {total_loss / len(iterator)}\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbdipjbhOypQ"
      },
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']  # no deacy parameters\n",
        "optimizer_grouped_parameters = [\n",
        "  {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "   'weight_decay': 0.01},\n",
        "  {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "   'weight_decay': 0.0}               \n",
        "]\n",
        "\n",
        "EPOCH_NUM = 2\n",
        "\n",
        "# https://paperswithcode.com/method/slanted-triangular-learning-rates\n",
        "# triangular learning rate; linearly grows until half of first epoch, then linearly decays\n",
        "warmup_steps = 10 ** 3\n",
        "total_steps = len(train_iterator) * EPOCH_NUM - warmup_steps\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)\n",
        "# https://huggingface.co/transformers/main_classes/optimizer_schedules.html#transformers.get_linear_schedule_with_warmup\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_zSsDTJSLwl",
        "outputId": "e2431c6b-0434-4e5b-b590-aaab6a3e0905"
      },
      "source": [
        "for i in range(EPOCH_NUM):\n",
        "  print('=' * 50, f\"EPOCH {i}\", '=' * 50)\n",
        "  train(model, train_iterator, optimizer, scheduler)\n",
        "  evaluate(model, dev_iterator)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4738 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================================== EPOCH 0 ==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4738/4738 [33:50<00:00,  2.33it/s]\n",
            "  0%|          | 1/250 [00:00<00:46,  5.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.7879722559940165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [00:49<00:00,  5.04it/s]\n",
            "  0%|          | 0/4738 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "toxic roc_auc 0.4645959231425188\n",
            "severe_toxic roc_auc 0.2811907170861262\n",
            "obscene roc_auc 0.5619153504552318\n",
            "threat roc_auc 0.6512165057025574\n",
            "insult roc_auc 0.4484191559688391\n",
            "identity_hate roc_auc 0.62461988590918\n",
            "Evaluate loss 0.7879172563552856\n",
            "================================================== EPOCH 1 ==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4738/4738 [33:25<00:00,  2.36it/s]\n",
            "  0%|          | 0/250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.7879551610975841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [00:48<00:00,  5.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "toxic roc_auc 0.4645959231425188\n",
            "severe_toxic roc_auc 0.2811907170861262\n",
            "obscene roc_auc 0.5619153504552318\n",
            "threat roc_auc 0.6512165057025574\n",
            "insult roc_auc 0.4484191559688391\n",
            "identity_hate roc_auc 0.6246198859091802\n",
            "Evaluate loss 0.7879485487937927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_lo4qV1Sg28",
        "outputId": "63bc9531-7659-440c-b099-724e37418722"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "test_df = pd.read_csv(os.path.join(input_file_path, 'test.csv'))\n",
        "submission = pd.read_csv(os.path.join(input_file_path, 'sample_submission.csv'))\n",
        "columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "for i in tqdm(range(len(test_df) // BATCH_SIZE + 1)):\n",
        "  batch_df = test_df.iloc[i * BATCH_SIZE: (i + 1) * BATCH_SIZE]\n",
        "  assert (batch_df[\"id\"] == submission[\"id\"][i * BATCH_SIZE: (i + 1) * BATCH_SIZE]).all(), f\"Id mismatch\"\n",
        "\n",
        "  texts = []\n",
        "  for text in batch_df['comment_text'].tolist():\n",
        "    text = tokenizer.encode(text, add_special_tokens=True)\n",
        "    if len(text) > 120:\n",
        "      text = text[:119] + [tokenizer.sep_token_id]\n",
        "    texts.append(torch.LongTensor(text))\n",
        "  \n",
        "  x = pad_sequence(texts, batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
        "  mask = (x != tokenizer.pad_token_id).float().to(device)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    _, outputs = model(x, attention_mask=mask)\n",
        "  outputs = outputs.cpu().numpy()\n",
        "  submission.iloc[i * BATCH_SIZE: (i + 1) * BATCH_SIZE][columns] = outputs"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4787 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n",
            "100%|██████████| 4787/4787 [13:06<00:00,  6.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}